{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNzHRGy7RrjRVDSEqwQveRN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalDharpure/redis-langchain-ecommerce-chatbot/blob/main/Ecommerce_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egPvjrrU8-Nx"
      },
      "outputs": [],
      "source": [
        "%pip install redis pandas\n",
        "%pip install -U sentence-transformers\n",
        "%pip install openai\n",
        "%pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from redis.commands.search.field import VectorField\n",
        "from redis.commands.search.field import TextField\n",
        "from redis.commands.search.field import TagField\n",
        "from redis.commands.search.query import Query\n",
        "import redis\n",
        "import time\n",
        "\n",
        "redis_conn = redis.Redis(\n",
        "  host='redis-15188.c1.asia-northeast1-1.gce.cloud.redislabs.com:15188',\n",
        "  port=18975,\n",
        "  password='1jEwYv3Qfjy3dp1sLLf2SmSegnf15VDv')"
      ],
      "metadata": {
        "id": "L2y5O4o8-Bpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TEXT_LENGTH=512\n",
        "NUMBER_PRODUCTS=1000\n",
        "\n",
        "def auto_truncate(val):\n",
        "    return val[:MAX_TEXT_LENGTH]\n",
        "\n",
        "#Load Product data and truncate long text fields\n",
        "all_prods_df = pd.read_csv(\"product_data_train.csv\", converters={'bullet_point': auto_truncate,'item_keywords':auto_truncate,'item_name':auto_truncate})\n",
        "all_prods_df['primary_key'] = all_prods_df['item_id'] + '-' + all_prods_df['domain_name']\n",
        "all_prods_df['item_keywords'].replace('', np.nan, inplace=True)\n",
        "all_prods_df.dropna(subset=['item_keywords'], inplace=True)\n",
        "all_prods_df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "#get the first 1000 products with non-empty item keywords\n",
        "product_metadata = all_prods_df.head(NUMBER_PRODUCTS).to_dict(orient='index')\n",
        "\n",
        "all_prods_df.head()"
      ],
      "metadata": {
        "id": "2ybXZlrX-Blm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
        "\n",
        "\n",
        "item_keywords =  [product_metadata[i]['item_keywords']  for i in product_metadata.keys()]\n",
        "item_keywords_vectors = [ model.encode(sentence) for sentence in item_keywords]"
      ],
      "metadata": {
        "id": "Z9wJHtMF-Bhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(item_keywords_vectors)\n",
        "len(product_metadata)\n",
        "# Check one of the products\n",
        "product_metadata[0]"
      ],
      "metadata": {
        "id": "ul8AV_9X-Bdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_vectors(client, product_metadata, vector_dict, vector_field_name):\n",
        "    p = client.pipeline(transaction=False)\n",
        "    for index in product_metadata.keys():\n",
        "        #hash key\n",
        "        key='product:'+ str(index)+ ':' + product_metadata[index]['primary_key']\n",
        "\n",
        "        #hash values\n",
        "        item_metadata = product_metadata[index]\n",
        "        item_keywords_vector = vector_dict[index].astype(np.float32).tobytes()\n",
        "        item_metadata[vector_field_name]=item_keywords_vector\n",
        "\n",
        "        # HSET\n",
        "        p.hset(key,mapping=item_metadata)\n",
        "\n",
        "    p.execute()\n",
        "\n",
        "def create_flat_index (redis_conn,vector_field_name,number_of_vectors, vector_dimensions=512, distance_metric='L2'):\n",
        "    redis_conn.ft().create_index([\n",
        "        VectorField(vector_field_name, \"FLAT\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric, \"INITIAL_CAP\": number_of_vectors, \"BLOCK_SIZE\":number_of_vectors }),\n",
        "        TagField(\"product_type\"),\n",
        "        TextField(\"item_name\"),\n",
        "        TextField(\"item_keywords\"),\n",
        "        TagField(\"country\")\n",
        "    ])"
      ],
      "metadata": {
        "id": "-FF0e7Qs-BY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ITEM_KEYWORD_EMBEDDING_FIELD='item_keyword_vector'\n",
        "TEXT_EMBEDDING_DIMENSION=768\n",
        "NUMBER_PRODUCTS=1000\n",
        "\n",
        "print ('Loading and Indexing + ' +  str(NUMBER_PRODUCTS) + ' products')\n",
        "\n",
        "#flush all data\n",
        "redis_conn.flushall()\n",
        "\n",
        "#create flat index & load vectors\n",
        "create_flat_index(redis_conn, ITEM_KEYWORD_EMBEDDING_FIELD,NUMBER_PRODUCTS,TEXT_EMBEDDING_DIMENSION,'COSINE')\n",
        "load_vectors(redis_conn,product_metadata,item_keywords_vectors,ITEM_KEYWORD_EMBEDDING_FIELD)\n",
        ""
      ],
      "metadata": {
        "id": "x-hVzu2N-BUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3, openai_api_key=\"sk-....\")\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product_description\"],\n",
        "    template=\"Create comma seperated product keywords to perform a query on a amazon dataset for this user input: {product_description}\",\n",
        ")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "userinput = input(\"Hey im a E-commerce Chatbot, how can i help you today? \")\n",
        "print(\"User:\", userinput)\n",
        "# Run the chain only specifying the input variable.\n",
        "keywords = chain.run(userinput)\n",
        "\n",
        "\n",
        "topK=3\n",
        "#vectorize the query\n",
        "query_vector = model.encode(keywords).astype(np.float32).tobytes()\n",
        "\n",
        "#prepare the query\n",
        "q = Query(f'*=>[KNN {topK} @{ITEM_KEYWORD_EMBEDDING_FIELD} $vec_param AS vector_score]').sort_by('vector_score').paging(0,topK).return_fields('vector_score','item_name','item_id','item_keywords').dialect(2)\n",
        "params_dict = {\"vec_param\": query_vector}\n",
        "\n",
        "#Execute the query\n",
        "results = redis_conn.ft().search(q, query_params = params_dict)\n",
        "\n",
        "full_result_string = ''\n",
        "for product in results.docs:\n",
        "    full_result_string += product.item_name + ' ' + product.item_keywords + ' ' + product.item_id + \"\\n\\n\\n\"\n",
        "\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "template = \"\"\"You are a chatbot. Be kind, detailed and nice. Present the given queried search result in a nice way as answer to the user input. dont ask questions back! just take the given context\n",
        "\n",
        "{chat_history}\n",
        "Human: {user_msg}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"user_msg\"],\n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.8, openai_api_key=\"sk-....\"),\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "answer = llm_chain.predict(user_msg= f\"{full_result_string} ---\\n\\n {userinput}\")\n",
        "print(\"Bot:\", answer)\n",
        "time.sleep(0.5)\n",
        "\n",
        "while True:\n",
        "    follow_up = input(\"Anything else you want to ask about this topic?\")\n",
        "    print(\"User:\", follow_up)\n",
        "    answer = llm_chain.predict(\n",
        "        user_msg=follow_up\n",
        "    )\n",
        "    print(\"Bot:\", answer)\n",
        "    time.sleep(0.5)"
      ],
      "metadata": {
        "id": "fV_kPx8N-BH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}